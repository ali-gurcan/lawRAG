# Hugging Face Token (Llama modelleri i√ßin gerekli)
HF_TOKEN=your_huggingface_token_here

# Server Configuration
HOST=0.0.0.0
PORT=5001
DEBUG=false

# Cache Configuration
CACHE_DIR=cache
CACHE_ENABLED=true

# Model Configuration
EMBEDDING_MODEL=e5-large
LLM_MODEL=llama-8b
RERANKER_MODEL=ms-marco

# Retrieval Configuration
TOP_K=4
USE_HYBRID_SEARCH=true
USE_RERANKING=true
USE_QUERY_EXPANSION=true

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Confidence Configuration
CONFIDENCE_THRESHOLD=0.7
CONFIDENCE_ENABLED=true

# Streaming Configuration
STREAMING_ENABLED=true
STREAMING_CHUNK_SIZE=1
